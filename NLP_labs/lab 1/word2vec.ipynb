{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "word2vec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx5X-m5AK2c9",
        "colab_type": "code",
        "outputId": "d74a8ee0-bebc-4344-869b-3e352ad5d265",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torch.functional as F\n",
        "import torch.nn.functional as F\n",
        "import pandas\n",
        "import string\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "import tensorflow.contrib.keras as keras\n",
        "from keras.layers import concatenate\n",
        "\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "504R2ix1MsXg",
        "colab_type": "code",
        "outputId": "80d04f9e-7269-4bae-cc81-0e6ec95bae18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pip install torchvision"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGyEjMf-hLA3",
        "colab_type": "code",
        "outputId": "b28fb9af-4aec-4085-a8ea-fd80f8b89fa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oojmnkp_hCPF",
        "colab_type": "code",
        "outputId": "6743c20d-4000-4ae4-c1e2-efe3da04e4de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#Reading IRIS Dataset in Pandas Dataframe\n",
        "#url=\"https://drive.google.com/open?id=1ugMmBeWB2r1XvDoZkdcFyFvcXp3aZ3js\"\n",
        "engine='python'\n",
        "link=\"/content/drive/My Drive/Colab Notebooks/2sem/lab1/bbc-text.csv\"\n",
        "#link=\"/content/Iris.csv\"\n",
        "dt = pandas.read_csv(link)\n",
        "corpus_dt = dt.loc[dt.category=='business'].text\n",
        "print(corpus_dt.head(5))\n",
        "print(len(corpus_dt))\n",
        "corpus = corpus_dt.values.tolist()\n",
        "corpus = corpus[:30]\n",
        "print(type(corpus[0]))\n",
        " \n"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1     worldcom boss  left books alone  former worldc...\n",
            "11    virgin blue shares plummet 20% shares in austr...\n",
            "12    crude oil prices back above $50 cold weather a...\n",
            "15    s korean credit card firm rescued south korea ...\n",
            "18    japanese banking battle at an end japan s sumi...\n",
            "Name: text, dtype: object\n",
            "510\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf5huHf_O6_4",
        "colab_type": "code",
        "outputId": "2130226a-9692-4313-c03e-5510d2bd8cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "dt.category.unique()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['tech', 'business', 'sport', 'entertainment', 'politics'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VDBNKL_4Kfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clear_text(text):\n",
        "  clear_text = \"\"\n",
        "  ### to lower case\n",
        "  text = text.lower()\n",
        "  ### deleting punctuation symbols\n",
        "  for symbol in text: \n",
        "    if symbol not in string.punctuation :\n",
        "      clear_text += symbol\n",
        "  return clear_text\n",
        "\n",
        "\n",
        "\n",
        "for i, row in enumerate(corpus):\n",
        "    #row_new = clear_punctuation(row)\n",
        "    row = clear_text(row)\n",
        "    corpus[i] = row\n",
        "\n",
        "for row in corpus:\n",
        "    if '.' in row:\n",
        "          print(row)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_bSvzlDV95B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# names_0 = pandas.read_html('https://github.com/dominictarr/random-name/blob/master/first-names.txt')\n",
        "# names = []\n",
        "# for i in names_0:\n",
        "#   names.append(i[1])\n",
        "#   print(i[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn2cMtniJigl",
        "colab_type": "code",
        "outputId": "1f4a43ed-d078-4363-ba04-684bb349490c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def tokenize_corpus(corpus):\n",
        "    tokens = [x.split() for x in corpus]\n",
        "    return tokens\n",
        "\n",
        "def tokenize_corpus_nltp(row):\n",
        "  token_words_0 = word_tokenize(str(row))\n",
        "  token_words = []\n",
        "  #lancaster=LancasterStemmer()\n",
        "  porter = PorterStemmer()\n",
        "  for word in token_words_0:\n",
        "    if word in stopwords.words('english') or any(char.isdigit() for char in word):\n",
        "      continue\n",
        "    token_words.append(porter.stem(word))\n",
        "\n",
        "  return token_words\n",
        "\n",
        "tokenized_corpus = []\n",
        "#tokenized_corpus = tokenize_corpus(corpus)\n",
        "#print(len(corpus))\n",
        "\n",
        "for row_i in corpus:\n",
        "  tokenized_corpus.append(tokenize_corpus_nltp(row_i))\n",
        "\n",
        "print(tokenized_corpus[0])\n",
        "# for row in tokenized_corpus:\n",
        "#   for word in row:\n",
        "#     if '.' in word:\n",
        "#           print(word)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['worldcom', 'boss', 'left', 'book', 'alon', 'former', 'worldcom', 'boss', 'berni', 'ebber', 'accus', 'overse', 'fraud', 'never', 'made', 'account', 'decis', 'wit', 'told', 'juror', 'david', 'myer', 'made', 'comment', 'question', 'defenc', 'lawyer', 'argu', 'mr', 'ebber', 'respons', 'worldcom', 'problem', 'phone', 'compani', 'collaps', 'prosecutor', 'claim', 'loss', 'hidden', 'protect', 'firm', 'share', 'mr', 'myer', 'alreadi', 'plead', 'guilti', 'fraud', 'assist', 'prosecutor', 'monday', 'defenc', 'lawyer', 'reid', 'weingarten', 'tri', 'distanc', 'client', 'alleg', 'cross', 'examin', 'ask', 'mr', 'myer', 'ever', 'knew', 'mr', 'ebber', 'make', 'account', 'decis', 'awar', 'mr', 'myer', 'repli', 'ever', 'know', 'mr', 'ebber', 'make', 'account', 'entri', 'worldcom', 'book', 'mr', 'weingarten', 'press', 'repli', 'wit', 'mr', 'myer', 'admit', 'order', 'fals', 'account', 'entri', 'request', 'former', 'worldcom', 'chief', 'financi', 'offic', 'scott', 'sullivan', 'defenc', 'lawyer', 'tri', 'paint', 'mr', 'sullivan', 'admit', 'fraud', 'testifi', 'later', 'trial', 'mastermind', 'behind', 'worldcom', 'account', 'hous', 'card', 'mr', 'ebber', 'team', 'meanwhil', 'look', 'portray', 'affabl', 'boss', 'admiss', 'pe', 'graduat', 'economist', 'whatev', 'abil', 'mr', 'ebber', 'transform', 'worldcom', 'rel', 'unknown', 'telecom', 'giant', 'investor', 'darl', 'late', 'worldcom', 'problem', 'mount', 'howev', 'competit', 'increas', 'telecom', 'boom', 'peter', 'firm', 'final', 'collaps', 'sharehold', 'lost', 'worker', 'lost', 'job', 'mr', 'ebber', 'trial', 'expect', 'last', 'two', 'month', 'found', 'guilti', 'former', 'ceo', 'face', 'substanti', 'jail', 'sentenc', 'firmli', 'declar', 'innoc']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7GDVdmtKGG7",
        "colab_type": "code",
        "outputId": "3597bb21-014c-4cc1-e8ec-a12f1c25b7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocabulary = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "\n",
        "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(vocabulary_size)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q78TRvzUKQRd",
        "colab_type": "code",
        "outputId": "57463a0d-5029-4dd5-ee79-585f0578a531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2idx\n",
        "if 'america' in word2idx:\n",
        "  print(word2idx['america'])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "252\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvSbEGeGWfzw",
        "colab_type": "code",
        "outputId": "b0f18b3a-333a-4bcd-b471-8d319f7daf0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "idx2word"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'worldcom',\n",
              " 1: 'boss',\n",
              " 2: 'left',\n",
              " 3: 'book',\n",
              " 4: 'alon',\n",
              " 5: 'former',\n",
              " 6: 'berni',\n",
              " 7: 'ebber',\n",
              " 8: 'accus',\n",
              " 9: 'overse',\n",
              " 10: 'fraud',\n",
              " 11: 'never',\n",
              " 12: 'made',\n",
              " 13: 'account',\n",
              " 14: 'decis',\n",
              " 15: 'wit',\n",
              " 16: 'told',\n",
              " 17: 'juror',\n",
              " 18: 'david',\n",
              " 19: 'myer',\n",
              " 20: 'comment',\n",
              " 21: 'question',\n",
              " 22: 'defenc',\n",
              " 23: 'lawyer',\n",
              " 24: 'argu',\n",
              " 25: 'mr',\n",
              " 26: 'respons',\n",
              " 27: 'problem',\n",
              " 28: 'phone',\n",
              " 29: 'compani',\n",
              " 30: 'collaps',\n",
              " 31: 'prosecutor',\n",
              " 32: 'claim',\n",
              " 33: 'loss',\n",
              " 34: 'hidden',\n",
              " 35: 'protect',\n",
              " 36: 'firm',\n",
              " 37: 'share',\n",
              " 38: 'alreadi',\n",
              " 39: 'plead',\n",
              " 40: 'guilti',\n",
              " 41: 'assist',\n",
              " 42: 'monday',\n",
              " 43: 'reid',\n",
              " 44: 'weingarten',\n",
              " 45: 'tri',\n",
              " 46: 'distanc',\n",
              " 47: 'client',\n",
              " 48: 'alleg',\n",
              " 49: 'cross',\n",
              " 50: 'examin',\n",
              " 51: 'ask',\n",
              " 52: 'ever',\n",
              " 53: 'knew',\n",
              " 54: 'make',\n",
              " 55: 'awar',\n",
              " 56: 'repli',\n",
              " 57: 'know',\n",
              " 58: 'entri',\n",
              " 59: 'press',\n",
              " 60: 'admit',\n",
              " 61: 'order',\n",
              " 62: 'fals',\n",
              " 63: 'request',\n",
              " 64: 'chief',\n",
              " 65: 'financi',\n",
              " 66: 'offic',\n",
              " 67: 'scott',\n",
              " 68: 'sullivan',\n",
              " 69: 'paint',\n",
              " 70: 'testifi',\n",
              " 71: 'later',\n",
              " 72: 'trial',\n",
              " 73: 'mastermind',\n",
              " 74: 'behind',\n",
              " 75: 'hous',\n",
              " 76: 'card',\n",
              " 77: 'team',\n",
              " 78: 'meanwhil',\n",
              " 79: 'look',\n",
              " 80: 'portray',\n",
              " 81: 'affabl',\n",
              " 82: 'admiss',\n",
              " 83: 'pe',\n",
              " 84: 'graduat',\n",
              " 85: 'economist',\n",
              " 86: 'whatev',\n",
              " 87: 'abil',\n",
              " 88: 'transform',\n",
              " 89: 'rel',\n",
              " 90: 'unknown',\n",
              " 91: 'telecom',\n",
              " 92: 'giant',\n",
              " 93: 'investor',\n",
              " 94: 'darl',\n",
              " 95: 'late',\n",
              " 96: 'mount',\n",
              " 97: 'howev',\n",
              " 98: 'competit',\n",
              " 99: 'increas',\n",
              " 100: 'boom',\n",
              " 101: 'peter',\n",
              " 102: 'final',\n",
              " 103: 'sharehold',\n",
              " 104: 'lost',\n",
              " 105: 'worker',\n",
              " 106: 'job',\n",
              " 107: 'expect',\n",
              " 108: 'last',\n",
              " 109: 'two',\n",
              " 110: 'month',\n",
              " 111: 'found',\n",
              " 112: 'ceo',\n",
              " 113: 'face',\n",
              " 114: 'substanti',\n",
              " 115: 'jail',\n",
              " 116: 'sentenc',\n",
              " 117: 'firmli',\n",
              " 118: 'declar',\n",
              " 119: 'innoc',\n",
              " 120: 'virgin',\n",
              " 121: 'blue',\n",
              " 122: 'plummet',\n",
              " 123: 'australian',\n",
              " 124: 'budget',\n",
              " 125: 'airlin',\n",
              " 126: 'plung',\n",
              " 127: 'warn',\n",
              " 128: 'steep',\n",
              " 129: 'fall',\n",
              " 130: 'full',\n",
              " 131: 'year',\n",
              " 132: 'profit',\n",
              " 133: 'said',\n",
              " 134: 'tax',\n",
              " 135: 'march',\n",
              " 136: 'would',\n",
              " 137: 'lower',\n",
              " 138: 'previou',\n",
              " 139: 'sluggish',\n",
              " 140: 'demand',\n",
              " 141: 'report',\n",
              " 142: 'previous',\n",
              " 143: 'novemb',\n",
              " 144: 'decemb',\n",
              " 145: 'continu',\n",
              " 146: 'execut',\n",
              " 147: 'brett',\n",
              " 148: 'godfrey',\n",
              " 149: 'own',\n",
              " 150: 'richard',\n",
              " 151: 'branson',\n",
              " 152: 'struggl',\n",
              " 153: 'fend',\n",
              " 154: 'pressur',\n",
              " 155: 'rival',\n",
              " 156: 'jetstar',\n",
              " 157: 'cut',\n",
              " 158: 'passeng',\n",
              " 159: 'number',\n",
              " 160: 'forecast',\n",
              " 161: 'approxim',\n",
              " 162: 'first',\n",
              " 163: 'quarter',\n",
              " 164: 'august',\n",
              " 165: 'due',\n",
              " 166: 'tough',\n",
              " 167: 'half',\n",
              " 168: 'slack',\n",
              " 169: 'rise',\n",
              " 170: 'fuel',\n",
              " 171: 'cost',\n",
              " 172: 'launch',\n",
              " 173: 'four',\n",
              " 174: 'ago',\n",
              " 175: 'roughli',\n",
              " 176: 'one',\n",
              " 177: 'third',\n",
              " 178: 'australia',\n",
              " 179: 'domest',\n",
              " 180: 'market',\n",
              " 181: 'nation',\n",
              " 182: 'carrier',\n",
              " 183: 'qanta',\n",
              " 184: 'fought',\n",
              " 185: 'back',\n",
              " 186: 'took',\n",
              " 187: 'sky',\n",
              " 188: 'may',\n",
              " 189: 'sydneylist',\n",
              " 190: 'recov',\n",
              " 191: 'slightli',\n",
              " 192: 'close',\n",
              " 193: 'wednesday',\n",
              " 194: 'major',\n",
              " 195: 'patrick',\n",
              " 196: 'corpor',\n",
              " 197: 'drop',\n",
              " 198: 'crude',\n",
              " 199: 'oil',\n",
              " 200: 'price',\n",
              " 201: 'cold',\n",
              " 202: 'weather',\n",
              " 203: 'across',\n",
              " 204: 'part',\n",
              " 205: 'unit',\n",
              " 206: 'state',\n",
              " 207: 'much',\n",
              " 208: 'europ',\n",
              " 209: 'push',\n",
              " 210: 'us',\n",
              " 211: 'barrel',\n",
              " 212: 'time',\n",
              " 213: 'almost',\n",
              " 214: 'three',\n",
              " 215: 'freez',\n",
              " 216: 'temperatur',\n",
              " 217: 'heavi',\n",
              " 218: 'snowfal',\n",
              " 219: 'heat',\n",
              " 220: 'stock',\n",
              " 221: 'low',\n",
              " 222: 'fresh',\n",
              " 223: 'valu',\n",
              " 224: 'dollar',\n",
              " 225: 'help',\n",
              " 226: 'carri',\n",
              " 227: 'mark',\n",
              " 228: 'sinc',\n",
              " 229: 'new',\n",
              " 230: 'york',\n",
              " 231: 'tuesday',\n",
              " 232: 'opec',\n",
              " 233: 'member',\n",
              " 234: 'saw',\n",
              " 235: 'reason',\n",
              " 236: 'output',\n",
              " 237: 'although',\n",
              " 238: 'peak',\n",
              " 239: 'reach',\n",
              " 240: 'octob',\n",
              " 241: 'well',\n",
              " 242: 'averag',\n",
              " 243: 'brent',\n",
              " 244: 'also',\n",
              " 245: 'rose',\n",
              " 246: 'london',\n",
              " 247: 'trade',\n",
              " 248: 'ad',\n",
              " 249: 'western',\n",
              " 250: 'north',\n",
              " 251: 'east',\n",
              " 252: 'america',\n",
              " 253: 'shiver',\n",
              " 254: 'unseason',\n",
              " 255: 'recent',\n",
              " 256: 'day',\n",
              " 257: 'declin',\n",
              " 258: 'fiveweek',\n",
              " 259: 'euro',\n",
              " 260: 'serv',\n",
              " 261: 'inflat',\n",
              " 262: 'move',\n",
              " 263: 'sharpli',\n",
              " 264: 'overnight',\n",
              " 265: 'follow',\n",
              " 266: 'chri',\n",
              " 267: 'fur',\n",
              " 268: 'senior',\n",
              " 269: 'strategist',\n",
              " 270: 'weaken',\n",
              " 271: 'obvious',\n",
              " 272: 'higher',\n",
              " 273: 'sever',\n",
              " 274: 'product',\n",
              " 275: 'unlik',\n",
              " 276: 'cite',\n",
              " 277: 'strong',\n",
              " 278: 'asia',\n",
              " 279: 'agre',\n",
              " 280: 'need',\n",
              " 281: 'suppli',\n",
              " 282: 'fathi',\n",
              " 283: 'bin',\n",
              " 284: 'shatwan',\n",
              " 285: 'libya',\n",
              " 286: 'minist',\n",
              " 287: 'reuter',\n",
              " 288: 'think',\n",
              " 289: 'unless',\n",
              " 290: 'watch',\n",
              " 291: 'global',\n",
              " 292: 'ensur',\n",
              " 293: 'excess',\n",
              " 294: 'arriv',\n",
              " 295: 'spring',\n",
              " 296: 'northern',\n",
              " 297: 'hemispher',\n",
              " 298: 'focu',\n",
              " 299: 'attent',\n",
              " 300: 'stockpil',\n",
              " 301: 'gasolin',\n",
              " 302: 'could',\n",
              " 303: 'forc',\n",
              " 304: 'eas',\n",
              " 305: 'korean',\n",
              " 306: 'credit',\n",
              " 307: 'rescu',\n",
              " 308: 'south',\n",
              " 309: 'korea',\n",
              " 310: 'largest',\n",
              " 311: 'avert',\n",
              " 312: 'liquid',\n",
              " 313: 'trillion',\n",
              " 314: 'bailout',\n",
              " 315: 'lg',\n",
              " 316: 'threaten',\n",
              " 317: 'huge',\n",
              " 318: 'debt',\n",
              " 319: 'creditor',\n",
              " 320: 'parent',\n",
              " 321: 'step',\n",
              " 322: 'consortium',\n",
              " 323: 'group',\n",
              " 324: 'famili',\n",
              " 325: 'conglomer',\n",
              " 326: 'put',\n",
              " 327: 'stabilis',\n",
              " 328: 'seven',\n",
              " 329: 'million',\n",
              " 330: 'custom',\n",
              " 331: 'sent',\n",
              " 332: 'shockwav',\n",
              " 333: 'countri',\n",
              " 334: 'economi',\n",
              " 335: 'deal',\n",
              " 336: 'secur',\n",
              " 337: 'futur',\n",
              " 338: 'week',\n",
              " 339: 'control',\n",
              " 340: 'januari',\n",
              " 341: 'avoid',\n",
              " 342: 'bankruptci',\n",
              " 343: 'delist',\n",
              " 344: 'trigger',\n",
              " 345: 'massiv',\n",
              " 346: 'redempt',\n",
              " 347: 'agreement',\n",
              " 348: 'fund',\n",
              " 349: 'aid',\n",
              " 350: 'laah',\n",
              " 351: 'chonggyu',\n",
              " 352: 'director',\n",
              " 353: 'develop',\n",
              " 354: 'bank',\n",
              " 355: 'see',\n",
              " 356: 'convert',\n",
              " 357: 'equiti',\n",
              " 358: 'purpos',\n",
              " 359: 'capit',\n",
              " 360: 'inject',\n",
              " 361: 'goal',\n",
              " 362: 'met',\n",
              " 363: 'kim',\n",
              " 364: 'analyst',\n",
              " 365: 'sejong',\n",
              " 366: 'consum',\n",
              " 367: 'slowli',\n",
              " 368: 'crisi',\n",
              " 369: 'bubbl',\n",
              " 370: 'burst',\n",
              " 371: 'fell',\n",
              " 372: 'repay',\n",
              " 373: 'return',\n",
              " 374: 'septemb',\n",
              " 375: 'thrown',\n",
              " 376: 'exchang',\n",
              " 377: 'exce',\n",
              " 378: 'asset',\n",
              " 379: 'run',\n",
              " 380: 'japanes',\n",
              " 381: 'battl',\n",
              " 382: 'end',\n",
              " 383: 'japan',\n",
              " 384: 'sumitomo',\n",
              " 385: 'mitsui',\n",
              " 386: 'withdrawn',\n",
              " 387: 'takeov',\n",
              " 388: 'offer',\n",
              " 389: 'ufj',\n",
              " 390: 'hold',\n",
              " 391: 'enabl',\n",
              " 392: 'latter',\n",
              " 393: 'merg',\n",
              " 394: 'mitsubishi',\n",
              " 395: 'tokyo',\n",
              " 396: 'counterpart',\n",
              " 397: 'friday',\n",
              " 398: 'clear',\n",
              " 399: 'way',\n",
              " 400: 'conclud',\n",
              " 401: 'yen',\n",
              " 402: 'creat',\n",
              " 403: 'world',\n",
              " 404: 'biggest',\n",
              " 405: 'exit',\n",
              " 406: 'high',\n",
              " 407: 'profil',\n",
              " 408: 'fight',\n",
              " 409: 'histori',\n",
              " 410: 'fourthlargest',\n",
              " 411: 'centr',\n",
              " 412: 'fierc',\n",
              " 413: 'bid',\n",
              " 414: 'thirdlargest',\n",
              " 415: 'tabl',\n",
              " 416: 'manag',\n",
              " 417: 'known',\n",
              " 418: 'prefer',\n",
              " 419: 'mtfg',\n",
              " 420: 'secondlargest',\n",
              " 421: 'concern',\n",
              " 422: 'rais',\n",
              " 423: 'absorb',\n",
              " 424: 'defeat',\n",
              " 425: 'believ',\n",
              " 426: 'accept',\n",
              " 427: 'ufjmtfg',\n",
              " 428: 'merger',\n",
              " 429: 'statement',\n",
              " 430: 'given',\n",
              " 431: 'ongo',\n",
              " 432: 'integr',\n",
              " 433: 'oper',\n",
              " 434: 'persist',\n",
              " 435: 'propos',\n",
              " 436: 'best',\n",
              " 437: 'interest',\n",
              " 438: 'largestev',\n",
              " 439: 'still',\n",
              " 440: 'approv',\n",
              " 441: 'formal',\n",
              " 442: 'turn',\n",
              " 443: 'deepen',\n",
              " 444: 'tie',\n",
              " 445: 'daiwa',\n",
              " 446: 'anoth',\n",
              " 447: 'set',\n",
              " 448: 'ventur',\n",
              " 449: 'specul',\n",
              " 450: 'lead',\n",
              " 451: 'fullblown',\n",
              " 452: 'increasingli',\n",
              " 453: 'seek',\n",
              " 454: 'allianc',\n",
              " 455: 'boost',\n",
              " 456: 'insur',\n",
              " 457: 'charg',\n",
              " 458: 'stem',\n",
              " 459: 'investig',\n",
              " 460: 'industri',\n",
              " 461: 'malpractic',\n",
              " 462: 'american',\n",
              " 463: 'intern',\n",
              " 464: 'aig',\n",
              " 465: 'marsh',\n",
              " 466: 'mclennan',\n",
              " 467: 'latest',\n",
              " 468: 'attorney',\n",
              " 469: 'gener',\n",
              " 470: 'eliot',\n",
              " 471: 'spitzer',\n",
              " 472: 'obtain',\n",
              " 473: 'nine',\n",
              " 474: 'plea',\n",
              " 475: 'highest',\n",
              " 476: 'rank',\n",
              " 477: 'vice',\n",
              " 478: 'presid',\n",
              " 479: 'joshua',\n",
              " 480: 'bewlay',\n",
              " 481: 'feloni',\n",
              " 482: 'count',\n",
              " 483: 'scheme',\n",
              " 484: 'defraud',\n",
              " 485: 'prison',\n",
              " 486: 'spokeswoman',\n",
              " 487: 'longer',\n",
              " 488: 'whether',\n",
              " 489: 'rig',\n",
              " 490: 'fix',\n",
              " 491: 'pay',\n",
              " 492: 'settl',\n",
              " 493: 'lawsuit',\n",
              " 494: 'file',\n",
              " 495: 'settlement',\n",
              " 496: 'neither',\n",
              " 497: 'deni',\n",
              " 498: 'german',\n",
              " 499: 'growth',\n",
              " 500: 'goe',\n",
              " 501: 'revers',\n",
              " 502: 'germani',\n",
              " 503: 'shrank',\n",
              " 504: 'upset',\n",
              " 505: 'hope',\n",
              " 506: 'sustain',\n",
              " 507: 'recoveri',\n",
              " 508: 'figur',\n",
              " 509: 'confound',\n",
              " 510: 'expans',\n",
              " 511: 'fourth',\n",
              " 512: 'feder',\n",
              " 513: 'statist',\n",
              " 514: 'whole',\n",
              " 515: 'contract',\n",
              " 516: 'earlier',\n",
              " 517: 'estim',\n",
              " 518: 'zero',\n",
              " 519: 'standstil',\n",
              " 520: 'juli',\n",
              " 521: 'onward',\n",
              " 522: 'reliant',\n",
              " 523: 'export',\n",
              " 524: 'get',\n",
              " 525: 'track',\n",
              " 526: 'unemploy',\n",
              " 527: 'five',\n",
              " 528: 'impend',\n",
              " 529: 'welfar',\n",
              " 530: 'mean',\n",
              " 531: 'kept',\n",
              " 532: 'money',\n",
              " 533: 'includ',\n",
              " 534: 'volkswagen',\n",
              " 535: 'daimlerchrysl',\n",
              " 536: 'siemen',\n",
              " 537: 'spent',\n",
              " 538: 'talk',\n",
              " 539: 'union',\n",
              " 540: 'trim',\n",
              " 541: 'accord',\n",
              " 542: 'destati',\n",
              " 543: 'outweigh',\n",
              " 544: 'weak',\n",
              " 545: 'relentless',\n",
              " 546: 'hit',\n",
              " 547: 'oversea',\n",
              " 548: 'effect',\n",
              " 549: 'depress',\n",
              " 550: 'prospect',\n",
              " 551: 'eurozon',\n",
              " 552: 'rate',\n",
              " 553: 'offici',\n",
              " 554: 'rateset',\n",
              " 555: 'european',\n",
              " 556: 'central',\n",
              " 557: 'begin',\n",
              " 558: 'threat',\n",
              " 559: 'prompt',\n",
              " 560: 'fear',\n",
              " 561: 'ecb',\n",
              " 562: 'mandat',\n",
              " 563: 'show',\n",
              " 564: 'slight',\n",
              " 565: 'home',\n",
              " 566: 'uk',\n",
              " 567: 'season',\n",
              " 568: 'adjust',\n",
              " 569: 'februari',\n",
              " 570: 'say',\n",
              " 571: 'nationwid',\n",
              " 572: 'build',\n",
              " 573: 'societi',\n",
              " 574: 'annual',\n",
              " 575: 'lowest',\n",
              " 576: 'june',\n",
              " 577: 'halv',\n",
              " 578: 'cool',\n",
              " 579: 'mortgag',\n",
              " 580: 'near',\n",
              " 581: 'england',\n",
              " 582: 'shown',\n",
              " 583: 'went',\n",
              " 584: 'alex',\n",
              " 585: 'bannist',\n",
              " 586: 'head',\n",
              " 587: 'downturn',\n",
              " 588: 'barclay',\n",
              " 589: 'woolwich',\n",
              " 590: 'properti',\n",
              " 591: 'summer',\n",
              " 592: 'pricewaterhousecoop',\n",
              " 593: 'pwc',\n",
              " 594: 'overvalu',\n",
              " 595: 'stand',\n",
              " 596: 'homeown',\n",
              " 597: 'next',\n",
              " 598: 'six',\n",
              " 599: 'level',\n",
              " 600: 'current',\n",
              " 601: 'key',\n",
              " 602: 'happen',\n",
              " 603: 'alway',\n",
              " 604: 'thought',\n",
              " 605: 'small',\n",
              " 606: 'risen',\n",
              " 607: 'pace',\n",
              " 608: 'rang',\n",
              " 609: 'predict',\n",
              " 610: 'evid',\n",
              " 611: 'slowdown',\n",
              " 612: 'emerg',\n",
              " 613: 'lend',\n",
              " 614: 'releas',\n",
              " 615: 'loan',\n",
              " 616: 'past',\n",
              " 617: 'seen',\n",
              " 618: 'reveal',\n",
              " 619: 'fewer',\n",
              " 620: 'overal',\n",
              " 621: 'margin',\n",
              " 622: 'eye',\n",
              " 623: 'amidst',\n",
              " 624: 'econom',\n",
              " 625: 'nikkei',\n",
              " 626: 'index',\n",
              " 627: 'gain',\n",
              " 628: 'point',\n",
              " 629: 'toward',\n",
              " 630: 'morgan',\n",
              " 631: 'stanley',\n",
              " 632: 'naoki',\n",
              " 633: 'kamiyama',\n",
              " 634: 'optim',\n",
              " 635: 'contrast',\n",
              " 636: 'pessim',\n",
              " 637: 'busi',\n",
              " 638: 'commun',\n",
              " 639: 'quarterli',\n",
              " 640: 'tankan',\n",
              " 641: 'survey',\n",
              " 642: 'manufactur',\n",
              " 643: 'confid',\n",
              " 644: 'slower',\n",
              " 645: 'stronger',\n",
              " 646: 'weaker',\n",
              " 647: 'blame',\n",
              " 648: 'despit',\n",
              " 649: 'trader',\n",
              " 650: 'strength',\n",
              " 651: 'benefit',\n",
              " 652: 'slide',\n",
              " 653: 'recess',\n",
              " 654: 'structur',\n",
              " 655: 'reform',\n",
              " 656: 'within',\n",
              " 657: 'anticip',\n",
              " 658: 'sector',\n",
              " 659: 'bad',\n",
              " 660: 'standard',\n",
              " 661: 'life',\n",
              " 662: 'polici',\n",
              " 663: 'bonus',\n",
              " 664: 'mutual',\n",
              " 665: 'withprofit',\n",
              " 666: 'policyhold',\n",
              " 667: 'bonu',\n",
              " 668: 'pension',\n",
              " 669: 'reduc',\n",
              " 670: 'sixth',\n",
              " 671: 'poor',\n",
              " 672: 'design',\n",
              " 673: 'smooth',\n",
              " 674: 'trough',\n",
              " 675: 'volatil',\n",
              " 676: 'good',\n",
              " 677: 'reserv',\n",
              " 678: 'even',\n",
              " 679: 'perform',\n",
              " 680: 'badli',\n",
              " 681: 'slump',\n",
              " 682: 'throughout',\n",
              " 683: 'came',\n",
              " 684: 'critic',\n",
              " 685: 'stick',\n",
              " 686: 'invest',\n",
              " 687: 'outperform',\n",
              " 688: 'long',\n",
              " 689: 'term',\n",
              " 690: 'feel',\n",
              " 691: 'norwich',\n",
              " 692: 'axa',\n",
              " 693: 'sun',\n",
              " 694: 'john',\n",
              " 695: 'gill',\n",
              " 696: 'divis',\n",
              " 697: 'partli',\n",
              " 698: 'compens',\n",
              " 699: 'addit',\n",
              " 700: 'meant',\n",
              " 701: 'longterm',\n",
              " 702: 'histor',\n",
              " 703: 'maintain',\n",
              " 704: 'payout',\n",
              " 705: 'type',\n",
              " 706: 'similar',\n",
              " 707: 'period',\n",
              " 708: 'announc',\n",
              " 709: 'float',\n",
              " 710: 'pernod',\n",
              " 711: 'lift',\n",
              " 712: 'domecq',\n",
              " 713: 'drink',\n",
              " 714: 'food',\n",
              " 715: 'alli',\n",
              " 716: 'target',\n",
              " 717: 'franc',\n",
              " 718: 'ricard',\n",
              " 719: 'wall',\n",
              " 720: 'street',\n",
              " 721: 'journal',\n",
              " 722: 'suggest',\n",
              " 723: 'french',\n",
              " 724: 'spirit',\n",
              " 725: 'consid',\n",
              " 726: 'yet',\n",
              " 727: 'contact',\n",
              " 728: 'gmt',\n",
              " 729: 'pari',\n",
              " 730: 'slip',\n",
              " 731: 'acquisit',\n",
              " 732: 'refus',\n",
              " 733: 'specif',\n",
              " 734: 'purchas',\n",
              " 735: 'seagram',\n",
              " 736: 'propel',\n",
              " 737: 'top',\n",
              " 738: 'twothird',\n",
              " 739: 'bought',\n",
              " 740: 'leader',\n",
              " 741: 'diageo',\n",
              " 742: 'smaller',\n",
              " 743: 'capitalis',\n",
              " 744: 'buy',\n",
              " 745: 'glenmorangi',\n",
              " 746: 'scotland',\n",
              " 747: 'premier',\n",
              " 748: 'whiski',\n",
              " 749: 'luxuri',\n",
              " 750: 'lvmh',\n",
              " 751: 'brand',\n",
              " 752: 'chiva',\n",
              " 753: 'regal',\n",
              " 754: 'scotch',\n",
              " 755: 'havana',\n",
              " 756: 'club',\n",
              " 757: 'rum',\n",
              " 758: 'jacob',\n",
              " 759: 'creek',\n",
              " 760: 'wine',\n",
              " 761: 'big',\n",
              " 762: 'name',\n",
              " 763: 'malibu',\n",
              " 764: 'courvoisi',\n",
              " 765: 'brandi',\n",
              " 766: 'stolichnaya',\n",
              " 767: 'vodka',\n",
              " 768: 'ballantin',\n",
              " 769: 'snack',\n",
              " 770: 'chain',\n",
              " 771: 'dunkin',\n",
              " 772: 'donut',\n",
              " 773: 'baskinrobbin',\n",
              " 774: 'ice',\n",
              " 775: 'cream',\n",
              " 776: 'wsj',\n",
              " 777: 'ripe',\n",
              " 778: 'consolid',\n",
              " 779: 'dealt',\n",
              " 780: 'problemat',\n",
              " 781: 'portfolio',\n",
              " 782: 'improv',\n",
              " 783: 'fastfood',\n",
              " 784: 'ukrain',\n",
              " 785: 'privatis',\n",
              " 786: 'check',\n",
              " 787: 'review',\n",
              " 788: 'dozen',\n",
              " 789: 'sale',\n",
              " 790: 'administr',\n",
              " 791: 'tackl',\n",
              " 792: 'corrupt',\n",
              " 793: 'viktor',\n",
              " 794: 'yushchenko',\n",
              " 795: 'less',\n",
              " 796: 'case',\n",
              " 797: 'mention',\n",
              " 798: 'cover',\n",
              " 799: 'mani',\n",
              " 800: 'oust',\n",
              " 801: 'longserv',\n",
              " 802: 'leonid',\n",
              " 803: 'kuchma',\n",
              " 804: 'want',\n",
              " 805: 'closer',\n",
              " 806: 'link',\n",
              " 807: 'separ',\n",
              " 808: 'eu',\n",
              " 809: 'organis',\n",
              " 810: 'prepar',\n",
              " 811: 'brussel',\n",
              " 812: 'meet',\n",
              " 813: 'georg',\n",
              " 814: 'w',\n",
              " 815: 'bush',\n",
              " 816: 'atlant',\n",
              " 817: 'treati',\n",
              " 818: 'nato',\n",
              " 819: 'nonnato',\n",
              " 820: 'invit',\n",
              " 821: 'attend',\n",
              " 822: 'summit',\n",
              " 823: 'moscowback',\n",
              " 824: 'presidenti',\n",
              " 825: 'candid',\n",
              " 826: 'prime',\n",
              " 827: 'yanukovych',\n",
              " 828: 'poll',\n",
              " 829: 'secret',\n",
              " 830: 'wish',\n",
              " 831: 'transpar',\n",
              " 832: 'yulia',\n",
              " 833: 'tymoshenko',\n",
              " 834: 'spotlight',\n",
              " 835: 'among',\n",
              " 836: 'sooth',\n",
              " 837: 'fray',\n",
              " 838: 'nerv',\n",
              " 839: 'acknowledg',\n",
              " 840: 'shape',\n",
              " 841: 'law',\n",
              " 842: 'trust',\n",
              " 843: 'defend',\n",
              " 844: 'hundr',\n",
              " 845: 'thousand',\n",
              " 846: 'ukrainian',\n",
              " 847: 'steel',\n",
              " 848: 'produc',\n",
              " 849: 'krivorizhst',\n",
              " 850: 'sold',\n",
              " 851: 'pinchuk',\n",
              " 852: 'soninlaw',\n",
              " 853: 'formerpresid',\n",
              " 854: 'rinat',\n",
              " 855: 'akhmetov',\n",
              " 856: 'richest',\n",
              " 857: 'man',\n",
              " 858: 'viceprim',\n",
              " 859: 'oleg',\n",
              " 860: 'rybachuk',\n",
              " 861: 'call',\n",
              " 862: 'recognis',\n",
              " 863: 'take',\n",
              " 864: 'reward',\n",
              " 865: 'effort',\n",
              " 866: 'backlash',\n",
              " 867: 'relat',\n",
              " 868: 'understood',\n",
              " 869: 'readi',\n",
              " 870: 'membership',\n",
              " 871: 'progress',\n",
              " 872: 'topic',\n",
              " 873: 'visa',\n",
              " 874: 'requir',\n",
              " 875: 'deserv',\n",
              " 876: 'honest',\n",
              " 877: 'associ',\n",
              " 878: 'interview',\n",
              " 879: 'understand',\n",
              " 880: 'difficulti',\n",
              " 881: 'doubl',\n",
              " 882: 'find',\n",
              " 883: 'sympathet',\n",
              " 884: 'ear',\n",
              " 885: 'reiter',\n",
              " 886: 'support',\n",
              " 887: 'fast',\n",
              " 888: 'access',\n",
              " 889: 'wto',\n",
              " 890: 'possibl',\n",
              " 891: 'like',\n",
              " 892: 'claud',\n",
              " 893: 'veronrevil',\n",
              " 894: 'spokesman',\n",
              " 895: 'commission',\n",
              " 896: 'mandelson',\n",
              " 897: 'import',\n",
              " 898: 'pull',\n",
              " 899: 'togeth',\n",
              " 900: 'allow',\n",
              " 901: 'care',\n",
              " 902: 'russia',\n",
              " 903: 'border',\n",
              " 904: 'pragmat',\n",
              " 905: 'moscow',\n",
              " 906: 'etern',\n",
              " 907: 'strateg',\n",
              " 908: 'partner',\n",
              " 909: 'regul',\n",
              " 910: 'rule',\n",
              " 911: 'pain',\n",
              " 912: 'drug',\n",
              " 913: 'decid',\n",
              " 914: 'recommend',\n",
              " 915: 'painkil',\n",
              " 916: 'risk',\n",
              " 917: 'heart',\n",
              " 918: 'attack',\n",
              " 919: 'stroke',\n",
              " 920: 'fda',\n",
              " 921: 'advisori',\n",
              " 922: 'panel',\n",
              " 923: 'give',\n",
              " 924: 'verdict',\n",
              " 925: 'hear',\n",
              " 926: 'inhibitor',\n",
              " 927: 'celebrex',\n",
              " 928: 'vioxx',\n",
              " 929: 'shop',\n",
              " 930: 'merck',\n",
              " 931: 'sell',\n",
              " 932: 'patient',\n",
              " 933: 'justifi',\n",
              " 934: 'shelv',\n",
              " 935: 'easier',\n",
              " 936: 'legal',\n",
              " 937: 'peopl',\n",
              " 938: 'injur',\n",
              " 939: 'voluntarili',\n",
              " 940: 'stop',\n",
              " 941: 'caus',\n",
              " 942: 'fourthquart',\n",
              " 943: 'earn',\n",
              " 944: 'tumbl',\n",
              " 945: 'news',\n",
              " 946: 'asid',\n",
              " 947: 'vioxxrel',\n",
              " 948: 'litig',\n",
              " 949: 'alarm',\n",
              " 950: 'bell',\n",
              " 951: 'rung',\n",
              " 952: 'research',\n",
              " 953: 'note',\n",
              " 954: 'least',\n",
              " 955: 'pfizer',\n",
              " 956: 'user',\n",
              " 957: 'stomach',\n",
              " 958: 'bextra',\n",
              " 959: 'though',\n",
              " 960: 'harm',\n",
              " 961: 'reintroduct',\n",
              " 962: 'caught',\n",
              " 963: 'surpris',\n",
              " 964: 'withdrew',\n",
              " 965: 'base',\n",
              " 966: 'inform',\n",
              " 967: 'avail',\n",
              " 968: 'altern',\n",
              " 969: 'therapi',\n",
              " 970: 'thing',\n",
              " 971: 'chang',\n",
              " 972: 'light',\n",
              " 973: 'cardiovascular',\n",
              " 974: 'observ',\n",
              " 975: 'uniqu',\n",
              " 976: 'class',\n",
              " 977: 'explain',\n",
              " 978: 'thursday',\n",
              " 979: 'graham',\n",
              " 980: 'safeti',\n",
              " 981: 'realli',\n",
              " 982: 'appear',\n",
              " 983: 'calcul',\n",
              " 984: 'present',\n",
              " 985: 'senat',\n",
              " 986: 'dr',\n",
              " 987: 'death',\n",
              " 988: 'handl',\n",
              " 989: 'independ',\n",
              " 990: 'bodi',\n",
              " 991: 'place',\n",
              " 992: 'diseas',\n",
              " 993: 'medicin',\n",
              " 994: 'agenc',\n",
              " 995: 'doctor',\n",
              " 996: 'cautiou',\n",
              " 997: 'factor',\n",
              " 998: 'telegraph',\n",
              " 999: 'newspap',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_FnNckvKUXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window_size = 5\n",
        "idx_pairs = []\n",
        "# for each sentence\n",
        "for sentence in tokenized_corpus:\n",
        "    indices = [word2idx[word] for word in sentence]\n",
        "    # for each word, threated as center word\n",
        "    for center_word_pos in range(len(indices)):\n",
        "        # for each window position\n",
        "        for w in range(-window_size, window_size + 1):\n",
        "            context_word_pos = center_word_pos + w\n",
        "            # make soure not jump out sentence\n",
        "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
        "                continue\n",
        "            context_word_idx = indices[context_word_pos]\n",
        "            idx_pairs.append((indices[center_word_pos], context_word_idx))\n",
        "\n",
        "idx_pairs = np.array(idx_pairs) # it will be useful to have this as numpy array"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pRBS-TAKvEA",
        "colab_type": "code",
        "outputId": "aa307ff9-0d51-4500-b1d9-632c41b57430",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "idx_pairs[:10]"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 2],\n",
              "       [0, 3],\n",
              "       [0, 4],\n",
              "       [0, 5],\n",
              "       [1, 0],\n",
              "       [1, 2],\n",
              "       [1, 3],\n",
              "       [1, 4],\n",
              "       [1, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R76JAnrXLK8s",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/377/1*uYiqfNrUIzkdMrmkBWGMPw.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Xsy5_fAK-qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_layer(word_idx):\n",
        "    x = torch.zeros(vocabulary_size).float()\n",
        "    x[word_idx] = 1.0\n",
        "    return x\n",
        "  \n",
        "  #Input layer is just the center word encoded in one-hot manner. It dimensions are [1, vocabulary_size]\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLU--gGwLNLX",
        "colab_type": "code",
        "outputId": "14cc1fd9-18e5-4996-db6f-56fd489cd241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "embedding_dims = 5\n",
        "W1 = Variable(torch.randn(embedding_dims, vocabulary_size).float(), requires_grad=True)\n",
        "W2 = Variable(torch.randn(vocabulary_size, embedding_dims).float(), requires_grad=True)\n",
        "num_epochs = 100\n",
        "learning_rate = 0.01\n",
        "\n",
        "tmp = 0\n",
        "for epo in range(num_epochs):\n",
        "    loss_val = 0\n",
        "    for data, target in idx_pairs:\n",
        "        x = Variable(get_input_layer(data)).float()\n",
        "        y_true = Variable(torch.from_numpy(np.array([target])).long())\n",
        "\n",
        "        z1 = torch.matmul(W1, x)\n",
        "        z2 = torch.matmul(W2, z1)\n",
        "    \n",
        "        log_softmax = F.log_softmax(z2, dim=0)\n",
        "        # if tmp == 20: break\n",
        "        # print(log_softmax.shape)\n",
        "        # tmp+=1\n",
        "\n",
        "        loss = F.nll_loss(log_softmax.view(1,-1), y_true)\n",
        "        loss_val += loss.data.item()\n",
        "        loss.backward()\n",
        "        W1.data -= learning_rate * W1.grad.data\n",
        "        W2.data -= learning_rate * W2.grad.data\n",
        "\n",
        "        W1.grad.data.zero_()\n",
        "        W2.grad.data.zero_()\n",
        "    if epo % 10 == 0:    \n",
        "        print(f'Loss at epo {epo}: {loss_val/len(idx_pairs)}')\n",
        "\n",
        "print( W2.data)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss at epo 0: 8.746580366471997\n",
            "Loss at epo 10: 6.9083738879884065\n",
            "Loss at epo 20: 6.503587195289378\n",
            "Loss at epo 30: 6.277432989397596\n",
            "Loss at epo 40: 6.1512120940872945\n",
            "Loss at epo 50: 6.078165411594658\n",
            "Loss at epo 60: 6.030789164868921\n",
            "Loss at epo 70: 5.996752235241836\n",
            "Loss at epo 80: 5.97065891789973\n",
            "Loss at epo 90: 5.949907918863787\n",
            "tensor([[ 1.3272,  0.3841, -2.3564, -0.3970, -0.1378],\n",
            "        [ 1.8777,  1.1734, -1.6361, -0.7718, -0.9487],\n",
            "        [ 1.3316,  2.2833, -2.4953, -0.0746,  0.3325],\n",
            "        ...,\n",
            "        [-0.2610,  0.0441,  1.7209,  0.7601,  1.6780],\n",
            "        [-0.3103,  0.1508,  1.6325,  0.5758,  1.7628],\n",
            "        [-0.0217,  0.3780,  1.6474,  0.9501,  1.7794]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8WjK72wtO82",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3985a250-1979-41a8-9995-7b5c98e70ea8"
      },
      "source": [
        "# print(type(W2.data))\n",
        "# WW = W2.data.numpy()\n",
        "# print(type(WW))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH5CCBDNVA46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "8c83c14c-378c-4699-fb19-f576d6c97865"
      },
      "source": [
        "def get_closests_to(input_word):\n",
        "  word_index = -1\n",
        "  dist = []\n",
        "  WW = W2.data.numpy()\n",
        "\n",
        "  if input_word in word2idx:\n",
        "      print(word2idx[input_word])\n",
        "      word_index = word2idx[input_word]\n",
        "  else: return\n",
        "  for i in range(vocabulary_size):\n",
        "    if i == word_index: continue\n",
        "    tmp_res = np.dot(WW[i], WW[word_index])\n",
        "    dist.append([tmp_res, i])\n",
        "  \n",
        "  #dist = np.sort(dist) \n",
        "  dist = sorted(dist, key=lambda x: x[0], reverse=True) \n",
        "  print(dist[:10])\n",
        "  for i in range(10):\n",
        "    print(idx2word[dist[i][1]])\n",
        "\n",
        "\n",
        "get_closests_to('america')\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "252\n",
            "[[11.49666, 816], [11.461034, 817], [10.775593, 818], [10.632609, 250], [9.720532, 819], [9.365337, 253], [9.231295, 1560], [9.217537, 1744], [9.207045, 814], [9.018282, 1561]]\n",
            "atlant\n",
            "treati\n",
            "nato\n",
            "north\n",
            "nonnato\n",
            "shiver\n",
            "northeast\n",
            "ralli\n",
            "w\n",
            "eventu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT7jySxTNff4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpglGcqO27Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}